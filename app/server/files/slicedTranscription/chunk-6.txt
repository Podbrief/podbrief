 applying that term to this particular case, where I know the limits of the tooling, I use it for what it's good at, I avoid it for things that I know that it's bad at. And I'm just, it's just become another tool for me, and a useful tool, but not a life changing tool for me personally. And so even my own personal use, I've kind of hit that plateau where I'm like, okay, it fits into my workflows here, doesn't fit into it here, and I'm more productive because of it in this case, especially in like, give me 40 synonyms for this word, you know, like when it comes to words, it's really good at words. And so I use it for those things. When it comes to Elixir, it's just okay at Elixir. And so I don't use it quite as much. When it comes to TypeScript, it's better at TypeScript than it is at Elixir. And so I'll use it for TypeScript. But it forgets everything, it doesn't know anything after September 2021. I've run into this a bunch. So like new libraries and new releases, it knows nothing about, which is annoying. Drives me crazy. Totally. If you know something's a few years old, you can kind of ask it about it for the most part. And I think on the current plateau, we will get there with that kind of functionality where like, it's going to get better from here. It's going to have a better memory. It's going to have access to newer information because of the tooling and the processes and all the work going into greasing the skids of this current technology. But as far as another step function, like the next plateau, I don't, obviously, I didn't know where this one was coming from. I don't know where that is. I don't know when it is. I'm not sure what it's going to be like. But for now, it seems like just as a microcosm, like the era of full self-driving cars is just as far away as it was the last time we asked, right? Like we're still not there yet. They're better. There's more uses, but we still don't trust them to full self-drive. Well, they exist in San Francisco, right? Like I see them every day in San Francisco. Okay. So in limited domains, limited context, but like what you would consider the AGI of driving, which is you drop me a human into pretty much any circumstance I've been driving for 25 years. Okay. Maybe certain machines I can't drive, but like, give me the sun in my eyes. Give me the ice. Give me the place I'd never been. And like, I can figure it out, roughly speaking. Of course, we still have tons of crashes and stuff, but like that level of full self-driving to me, it just feels so far away still. Yeah, that's fair. And like, I'm Canadian. I've been saying a long time, driving snow, then I'll be impressed. Right. Until then, I'm not buying it. It's a whole different game, isn't it? Yeah, exactly. Well, even for humans, it's challenging. Oh, it is challenging. Yeah. And scary. I've been wrecked before. Brought back some PTSD, man. In terms of AI, some really interesting uses I've done recently. I'd like to share one because I just didn't consider doing this. And this is where I think it's like leveled up humanity in subtle ways. So this weekend, I was barbecuing because that's what you do on holiday weekends, at least here in the States, it was Labor Day weekend. And I had some family over and I had these gigantic Texas-sized potatoes. So I was going to make baked potatoes. And they were just like baked potatoes. They were smoked baked potatoes. And so I wanted to go true barbecue and do low and slow, 225, super smoke, for as long as it takes to get to 205. And I haven't had breakfast yet. I'm getting hungry. Sorry about that. You're killing us. We didn't have enough time though. So that was my plan. So I had to alter my plan. I'm like, you know what? Let me ask Chad GPT. I've got this amount of time and I've got this potato. And I want to get to this temperature. Rather than me get flustered and skip it and go to a restaurant, I've got this much time, Chad GPT. I got this, the Traeger, whatever model, and I can get to this temperature. And I fed it this data essentially. I said, well, you know, if you put it at this temperature, you'll meet your criteria for getting this potato to doneness in this amount of time. So rather than skip the meal, I used Chad GPT to sort of reverse engineer, you know, thermodynamics essentially. Like how do I get the potato to 205 target internal temperature? And to what temperature do I have to cook it at for this amount of time? And they were like 275 or whatever. I forget what the number was. But it was like, it wasn't 225 where I wanted to be at, which is, you know, low and slow. And then the other use I did recently was I have a Denon 4400 home theater receiver in my media room in my house. And on Plex, I've got all these different films and they're all on different. And you got this one that's, you know, DTS HD 5.1. You've got this other one that's true HD 7.1. And these are all like original sound formats in the sound studio. And your Denon receiver, any given home theater receiver can process that sound into the speakers that you have available and make it sound good. It's a sound processing thing. So I'm like, well, Chad GPT helped me figure this out. Like if I've got these available settings in my Denon to translate this sound into my speakers, into my format, what's the best one to use given its original format? And I never thought to use it like that. I would just guess, read the manual or something like that. And which one does it map to? So I had Chad GPT make me this matrix. So I took all the films I have, all the original sound formats and all the available ones in the 5.1 of the 7.1 settings. And so now I don't have to guess anymore, like which one to use. I just go to this grid that Chad GPT may be based on what I have available and what the film might be. And boom, I'm using the right sound processing on my Denon. Like those are things that make subtle advancements in today's. Like, am I earning a million dollars because of that advancement? Heck no. But am I enjoying my home theater better and cooking potatoes faster to the degree I've got to within a certain amount of time? Yes. That's amazing. If that isn't AI making your life better, I don't know what it. That's what I'm talking about, right? Yeah. That is good life right there. Oh, for sure. Yeah. The current plateau is much nicer than it was prior to being here. Like I say, I'm in the trough of delusion because I've kind of, I've hit up against the seams or the edges of what it can and can't do. But the stuff that I can do, Adam, like you're describing, like life is a lot better because I can say, give me the FFMPEG command for this thing. And then I don't have to go read the man page and I Google way less. And I just ask it for things that it knows. And, but when you first start to use it, you don't know the boundaries of its abilities. And so you tend to be like, it can do everything and it's always right. And then you're like, wait a second, chill out, Jared. It can't do everything. And it's not always right. It's wrong a lot. Or because it can't do this most imaginable thing you want it to do. Therefore it's a failure. You know, like, can you scour the internet, find this doc to buy and make me a millionaire in six months? If it can't, it's that question. Has it failed you? No, it has not. Because that's not quite where it's at. That's the people that have failed. You are on Twitter telling you that it can do that for you. Right. That's right. Right. And they're also telling you, you know, like doom is upon us. And like, I do wonder the people are AI doom. We should be scared of GPT-4. Like, have you ever used GPT-4? I understand that it's changing and it's going to get better, but like these are fundamental restrictions on what it can do. I totally agree with Jared. You bump up against the walls and you're like, it's going to get better, but it's not going to be like a transformative wizard anytime soon. Right. What's interesting to me is like, if we talk about that open letter published, now it was probably last year, maybe it was this spring. Oh yeah. That looks really funny in retrospect, doesn't it? Yeah. That letter is signed by really smart people. I mean, you talked, you, you mentioned the Unikowski, uh, Udkowski, and he actually, I found a time article where he says that that letter didn't go far enough. And so he really is, as you said, kind of the high priest of this particular belief. He's like way on the edge of doom. What's the letter say? Give a summary. The letter says we should stop all AI research until we understand what the hell is going on. That's, that's basically. Yeah, exactly. But it was signed by a lot of people and people that are like, they're not, uh, Joe Schmo. Oh yeah, yeah. Totally very impressive names. I know a couple of them. Is there a blockchain to verify they signed it though? They didn't protest and say they didn't sign it. Okay. We've also found the boundaries of what blockchain can do for us. And, but so they did, I mean, you can argue individuals and go ask them, but there's just a lot of names, a lot of people who are leaders in AI things. This guy is no slouch, uh, far more impressive than myself, but you wonder, I don't know, like how all those smart people could land on a position that's so strong. And then you have a lot of other smart people that land on a position that's so opposite strong. It just is a interesting conundrum, I guess, maybe because none of us know what's going to happen. What do you think, John? Like, it's hard to dismiss that many names on a, on a signed letter, but at the same time, we just kind of are dismissive of it because it seems like it's not right. At least for now. Well, I think it goes back to what you're saying with the plateau. I think people who saw that did not think we were going to plateau. They thought things were just going to keep accelerating from January through March, April. Just exponential progress. Yeah, exactly. You know, June would be even crazier than March and September would be beyond crazy. Right. As you say, we have pretty clearly seen that that is not the case, you know, nothing dramatic has changed. So like, I think it was, it's a reasonable concern. I would have argued strongly against it at the time. You know, that there's always plateaus. You never get uninterrupted exponential growth, you know, except maybe Moore's law. And that's like a one-off. Right. I understand where they were coming from. It just, it looks like quickly, like they made a bad call now. While we're hearing this prediction, let me share one more other today leveling up. It's really good. You're going to love this one. Do either of you manage hard drives? Jerry's going to laugh about this one. Because he does not manage hard drives, just the one that's on his machine. Yeah, I really try not to. I've transcended in life. Right. I'm beyond. Well, as you know, most modern hard drives, whether there's an